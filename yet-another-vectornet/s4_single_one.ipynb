{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed6b93-758f-4f1f-9b4e-a8d8eff6f994",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training at epoch:0\n",
      "finished epoch 0: loss:188.807, lr: 0.001000, time: 0.305616sec\n",
      "start training at epoch:1\n",
      "finished epoch 1: loss:177.919, lr: 0.001000, time: 0.297568sec\n",
      "start training at epoch:2\n",
      "finished epoch 2: loss:169.694, lr: 0.001000, time: 0.298847sec\n",
      "start training at epoch:3\n",
      "finished epoch 3: loss:163.379, lr: 0.001000, time: 0.309509sec\n",
      "start training at epoch:4\n",
      "finished epoch 4: loss:158.576, lr: 0.001000, time: 0.298456sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.713329, minFDE:25.373226, MissRate:1.000000\n",
      "model saved to trained_params/epoch_4.valminade_12.713.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:5\n",
      "finished epoch 5: loss:154.828, lr: 0.001000, time: 0.299547sec\n",
      "start training at epoch:6\n",
      "finished epoch 6: loss:152.172, lr: 0.001000, time: 0.324385sec\n",
      "start training at epoch:7\n",
      "finished epoch 7: loss:150.208, lr: 0.001000, time: 0.300591sec\n",
      "start training at epoch:8\n",
      "epoch 8 step 9： loss:0.544342, lr: 0.001000, time: 0.300701sec\n",
      "finished epoch 8: loss:148.642, lr: 0.001000, time: 0.301085sec\n",
      "start training at epoch:9\n",
      "finished epoch 9: loss:147.312, lr: 0.000300, time: 0.301873sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.595684, minFDE:25.157326, MissRate:1.000000\n",
      "model saved to trained_params/epoch_9.valminade_12.596.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:10\n",
      "finished epoch 10: loss:146.134, lr: 0.000300, time: 0.307089sec\n",
      "start training at epoch:11\n",
      "finished epoch 11: loss:145.776, lr: 0.000300, time: 0.306680sec\n",
      "start training at epoch:12\n",
      "finished epoch 12: loss:145.402, lr: 0.000300, time: 0.297548sec\n",
      "start training at epoch:13\n",
      "finished epoch 13: loss:145.019, lr: 0.000300, time: 0.303006sec\n",
      "start training at epoch:14\n",
      "finished epoch 14: loss:144.639, lr: 0.000300, time: 0.300061sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.569860, minFDE:25.107723, MissRate:1.000000\n",
      "model saved to trained_params/epoch_14.valminade_12.570.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:15\n",
      "finished epoch 15: loss:144.255, lr: 0.000300, time: 0.303061sec\n",
      "start training at epoch:16\n",
      "finished epoch 16: loss:143.873, lr: 0.000300, time: 0.293617sec\n",
      "start training at epoch:17\n",
      "finished epoch 17: loss:143.511, lr: 0.000300, time: 0.371198sec\n",
      "start training at epoch:18\n",
      "epoch 18 step 19： loss:0.524278, lr: 0.000300, time: 0.316149sec\n",
      "finished epoch 18: loss:143.163, lr: 0.000300, time: 0.316617sec\n",
      "start training at epoch:19\n",
      "finished epoch 19: loss:142.823, lr: 0.000090, time: 0.303590sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.536241, minFDE:25.041297, MissRate:1.000000\n",
      "model saved to trained_params/epoch_19.valminade_12.536.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:20\n",
      "finished epoch 20: loss:142.485, lr: 0.000090, time: 0.304753sec\n",
      "start training at epoch:21\n",
      "finished epoch 21: loss:142.381, lr: 0.000090, time: 0.293652sec\n",
      "start training at epoch:22\n",
      "finished epoch 22: loss:142.275, lr: 0.000090, time: 0.301722sec\n",
      "start training at epoch:23\n",
      "finished epoch 23: loss:142.166, lr: 0.000090, time: 0.299949sec\n",
      "start training at epoch:24\n",
      "finished epoch 24: loss:142.057, lr: 0.000090, time: 0.303348sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.521930, minFDE:25.012826, MissRate:1.000000\n",
      "model saved to trained_params/epoch_24.valminade_12.522.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:25\n",
      "finished epoch 25: loss:141.945, lr: 0.000090, time: 0.301837sec\n",
      "start training at epoch:26\n",
      "finished epoch 26: loss:141.831, lr: 0.000090, time: 0.297412sec\n",
      "start training at epoch:27\n",
      "finished epoch 27: loss:141.716, lr: 0.000090, time: 0.302872sec\n",
      "start training at epoch:28\n",
      "epoch 28 step 29： loss:0.518555, lr: 0.000090, time: 0.297514sec\n",
      "finished epoch 28: loss:141.600, lr: 0.000090, time: 0.297901sec\n",
      "start training at epoch:29\n",
      "finished epoch 29: loss:141.483, lr: 0.000027, time: 0.306358sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.503873, minFDE:24.977697, MissRate:1.000000\n",
      "model saved to trained_params/epoch_29.valminade_12.504.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:30\n",
      "finished epoch 30: loss:141.365, lr: 0.000027, time: 0.302092sec\n",
      "start training at epoch:31\n",
      "finished epoch 31: loss:141.329, lr: 0.000027, time: 0.382782sec\n",
      "start training at epoch:32\n",
      "finished epoch 32: loss:141.292, lr: 0.000027, time: 0.301696sec\n",
      "start training at epoch:33\n",
      "finished epoch 33: loss:141.256, lr: 0.000027, time: 0.301148sec\n",
      "start training at epoch:34\n",
      "finished epoch 34: loss:141.219, lr: 0.000027, time: 0.299958sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.497650, minFDE:24.965679, MissRate:1.000000\n",
      "model saved to trained_params/epoch_34.valminade_12.498.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:35\n",
      "finished epoch 35: loss:141.182, lr: 0.000027, time: 0.301017sec\n",
      "start training at epoch:36\n",
      "finished epoch 36: loss:141.144, lr: 0.000027, time: 0.301630sec\n",
      "start training at epoch:37\n",
      "finished epoch 37: loss:141.107, lr: 0.000027, time: 0.301405sec\n",
      "start training at epoch:38\n",
      "epoch 38 step 39： loss:0.516609, lr: 0.000027, time: 0.304448sec\n",
      "finished epoch 38: loss:141.069, lr: 0.000027, time: 0.304888sec\n",
      "start training at epoch:39\n",
      "finished epoch 39: loss:141.031, lr: 0.000008, time: 0.294002sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.491073, minFDE:24.952862, MissRate:1.000000\n",
      "model saved to trained_params/epoch_39.valminade_12.491.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:40\n",
      "finished epoch 40: loss:140.993, lr: 0.000008, time: 0.297262sec\n",
      "start training at epoch:41\n",
      "finished epoch 41: loss:140.982, lr: 0.000008, time: 0.299978sec\n",
      "start training at epoch:42\n",
      "finished epoch 42: loss:140.970, lr: 0.000008, time: 0.302252sec\n",
      "start training at epoch:43\n",
      "finished epoch 43: loss:140.959, lr: 0.000008, time: 0.240880sec\n",
      "start training at epoch:44\n",
      "finished epoch 44: loss:140.947, lr: 0.000008, time: 0.300539sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.489025, minFDE:24.948820, MissRate:1.000000\n",
      "model saved to trained_params/epoch_44.valminade_12.489.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:45\n",
      "finished epoch 45: loss:140.935, lr: 0.000008, time: 0.314301sec\n",
      "start training at epoch:46\n",
      "finished epoch 46: loss:140.924, lr: 0.000008, time: 0.306328sec\n",
      "start training at epoch:47\n",
      "finished epoch 47: loss:140.912, lr: 0.000008, time: 0.305668sec\n",
      "start training at epoch:48\n",
      "epoch 48 step 49： loss:0.515992, lr: 0.000008, time: 0.303224sec\n",
      "finished epoch 48: loss:140.900, lr: 0.000008, time: 0.303619sec\n",
      "start training at epoch:49\n",
      "finished epoch 49: loss:140.888, lr: 0.000002, time: 0.300063sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.486860, minFDE:24.944591, MissRate:1.000000\n",
      "model saved to trained_params/epoch_49.valminade_12.487.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:50\n",
      "finished epoch 50: loss:140.877, lr: 0.000002, time: 0.301956sec\n",
      "start training at epoch:51\n",
      "finished epoch 51: loss:140.873, lr: 0.000002, time: 0.300890sec\n",
      "start training at epoch:52\n",
      "finished epoch 52: loss:140.869, lr: 0.000002, time: 0.301524sec\n",
      "start training at epoch:53\n",
      "finished epoch 53: loss:140.866, lr: 0.000002, time: 0.297891sec\n",
      "start training at epoch:54\n",
      "finished epoch 54: loss:140.862, lr: 0.000002, time: 0.302426sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.486187, minFDE:24.943288, MissRate:1.000000\n",
      "model saved to trained_params/epoch_54.valminade_12.486.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:55\n",
      "finished epoch 55: loss:140.859, lr: 0.000002, time: 0.302608sec\n",
      "start training at epoch:56\n",
      "finished epoch 56: loss:140.855, lr: 0.000002, time: 0.300301sec\n",
      "start training at epoch:57\n",
      "finished epoch 57: loss:140.852, lr: 0.000002, time: 0.300006sec\n",
      "start training at epoch:58\n",
      "epoch 58 step 59： loss:0.515801, lr: 0.000002, time: 0.293708sec\n",
      "finished epoch 58: loss:140.848, lr: 0.000002, time: 0.294055sec\n",
      "start training at epoch:59\n",
      "finished epoch 59: loss:140.844, lr: 0.000001, time: 0.309406sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.485498, minFDE:24.941956, MissRate:1.000000\n",
      "model saved to trained_params/epoch_59.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:60\n",
      "finished epoch 60: loss:140.841, lr: 0.000001, time: 0.294231sec\n",
      "start training at epoch:61\n",
      "finished epoch 61: loss:140.840, lr: 0.000001, time: 0.299681sec\n",
      "start training at epoch:62\n",
      "finished epoch 62: loss:140.839, lr: 0.000001, time: 0.302038sec\n",
      "start training at epoch:63\n",
      "finished epoch 63: loss:140.837, lr: 0.000001, time: 0.297396sec\n",
      "start training at epoch:64\n",
      "finished epoch 64: loss:140.836, lr: 0.000001, time: 0.305140sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.485291, minFDE:24.941553, MissRate:1.000000\n",
      "model saved to trained_params/epoch_64.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:65\n",
      "finished epoch 65: loss:140.835, lr: 0.000001, time: 0.315945sec\n",
      "start training at epoch:66\n",
      "finished epoch 66: loss:140.834, lr: 0.000001, time: 0.304017sec\n",
      "start training at epoch:67\n",
      "finished epoch 67: loss:140.833, lr: 0.000001, time: 0.301260sec\n",
      "start training at epoch:68\n",
      "epoch 68 step 69： loss:0.515742, lr: 0.000001, time: 0.299803sec\n",
      "finished epoch 68: loss:140.832, lr: 0.000001, time: 0.352564sec\n",
      "start training at epoch:69\n",
      "finished epoch 69: loss:140.831, lr: 0.000000, time: 0.246578sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.485083, minFDE:24.941147, MissRate:1.000000\n",
      "model saved to trained_params/epoch_69.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:70\n",
      "finished epoch 70: loss:140.830, lr: 0.000000, time: 0.308490sec\n",
      "start training at epoch:71\n",
      "finished epoch 71: loss:140.829, lr: 0.000000, time: 0.308619sec\n",
      "start training at epoch:72\n",
      "finished epoch 72: loss:140.829, lr: 0.000000, time: 0.303741sec\n",
      "start training at epoch:73\n",
      "finished epoch 73: loss:140.829, lr: 0.000000, time: 0.299583sec\n",
      "start training at epoch:74\n",
      "finished epoch 74: loss:140.828, lr: 0.000000, time: 0.365481sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.485020, minFDE:24.941024, MissRate:1.000000\n",
      "model saved to trained_params/epoch_74.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:75\n",
      "finished epoch 75: loss:140.828, lr: 0.000000, time: 0.306402sec\n",
      "start training at epoch:76\n",
      "finished epoch 76: loss:140.828, lr: 0.000000, time: 0.298018sec\n",
      "start training at epoch:77\n",
      "finished epoch 77: loss:140.827, lr: 0.000000, time: 0.297778sec\n",
      "start training at epoch:78\n",
      "epoch 78 step 79： loss:0.515724, lr: 0.000000, time: 0.302706sec\n",
      "finished epoch 78: loss:140.827, lr: 0.000000, time: 0.303125sec\n",
      "start training at epoch:79\n",
      "finished epoch 79: loss:140.827, lr: 0.000000, time: 0.297141sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484958, minFDE:24.940902, MissRate:1.000000\n",
      "model saved to trained_params/epoch_79.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:80\n",
      "finished epoch 80: loss:140.826, lr: 0.000000, time: 0.297558sec\n",
      "start training at epoch:81\n",
      "finished epoch 81: loss:140.826, lr: 0.000000, time: 0.306977sec\n",
      "start training at epoch:82\n",
      "finished epoch 82: loss:140.826, lr: 0.000000, time: 0.301027sec\n",
      "start training at epoch:83\n",
      "finished epoch 83: loss:140.826, lr: 0.000000, time: 0.298297sec\n",
      "start training at epoch:84\n",
      "finished epoch 84: loss:140.826, lr: 0.000000, time: 0.299957sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484939, minFDE:24.940865, MissRate:1.000000\n",
      "model saved to trained_params/epoch_84.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:85\n",
      "finished epoch 85: loss:140.826, lr: 0.000000, time: 0.245554sec\n",
      "start training at epoch:86\n",
      "finished epoch 86: loss:140.826, lr: 0.000000, time: 0.296906sec\n",
      "start training at epoch:87\n",
      "finished epoch 87: loss:140.826, lr: 0.000000, time: 0.297276sec\n",
      "start training at epoch:88\n",
      "epoch 88 step 89： loss:0.515719, lr: 0.000000, time: 0.373420sec\n",
      "finished epoch 88: loss:140.826, lr: 0.000000, time: 0.374022sec\n",
      "start training at epoch:89\n",
      "finished epoch 89: loss:140.826, lr: 0.000000, time: 0.309507sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484920, minFDE:24.940828, MissRate:1.000000\n",
      "model saved to trained_params/epoch_89.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:90\n",
      "finished epoch 90: loss:140.825, lr: 0.000000, time: 0.245214sec\n",
      "start training at epoch:91\n",
      "finished epoch 91: loss:140.825, lr: 0.000000, time: 0.297021sec\n",
      "start training at epoch:92\n",
      "finished epoch 92: loss:140.825, lr: 0.000000, time: 0.354739sec\n",
      "start training at epoch:93\n",
      "finished epoch 93: loss:140.825, lr: 0.000000, time: 0.301147sec\n",
      "start training at epoch:94\n",
      "finished epoch 94: loss:140.825, lr: 0.000000, time: 0.301333sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484914, minFDE:24.940817, MissRate:1.000000\n",
      "model saved to trained_params/epoch_94.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:95\n",
      "finished epoch 95: loss:140.825, lr: 0.000000, time: 0.296944sec\n",
      "start training at epoch:96\n",
      "finished epoch 96: loss:140.825, lr: 0.000000, time: 0.302193sec\n",
      "start training at epoch:97\n",
      "finished epoch 97: loss:140.825, lr: 0.000000, time: 0.305473sec\n",
      "start training at epoch:98\n",
      "epoch 98 step 99： loss:0.515717, lr: 0.000000, time: 0.305581sec\n",
      "finished epoch 98: loss:140.825, lr: 0.000000, time: 0.305952sec\n",
      "start training at epoch:99\n",
      "finished epoch 99: loss:140.825, lr: 0.000000, time: 0.302546sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484909, minFDE:24.940806, MissRate:1.000000\n",
      "model saved to trained_params/epoch_99.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:100\n",
      "finished epoch 100: loss:140.825, lr: 0.000000, time: 0.301350sec\n",
      "start training at epoch:101\n",
      "finished epoch 101: loss:140.825, lr: 0.000000, time: 0.298121sec\n",
      "start training at epoch:102\n",
      "finished epoch 102: loss:140.825, lr: 0.000000, time: 0.366249sec\n",
      "start training at epoch:103\n",
      "finished epoch 103: loss:140.825, lr: 0.000000, time: 0.298902sec\n",
      "start training at epoch:104\n",
      "finished epoch 104: loss:140.825, lr: 0.000000, time: 0.302165sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484907, minFDE:24.940803, MissRate:1.000000\n",
      "model saved to trained_params/epoch_104.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:105\n",
      "finished epoch 105: loss:140.825, lr: 0.000000, time: 0.297848sec\n",
      "start training at epoch:106\n",
      "finished epoch 106: loss:140.825, lr: 0.000000, time: 0.297267sec\n",
      "start training at epoch:107\n",
      "finished epoch 107: loss:140.825, lr: 0.000000, time: 0.297802sec\n",
      "start training at epoch:108\n",
      "epoch 108 step 109： loss:0.515717, lr: 0.000000, time: 0.294578sec\n",
      "finished epoch 108: loss:140.825, lr: 0.000000, time: 0.295023sec\n",
      "start training at epoch:109\n",
      "finished epoch 109: loss:140.825, lr: 0.000000, time: 0.301522sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940799, MissRate:1.000000\n",
      "model saved to trained_params/epoch_109.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:110\n",
      "finished epoch 110: loss:140.825, lr: 0.000000, time: 0.298287sec\n",
      "start training at epoch:111\n",
      "finished epoch 111: loss:140.825, lr: 0.000000, time: 0.297073sec\n",
      "start training at epoch:112\n",
      "finished epoch 112: loss:140.825, lr: 0.000000, time: 0.298267sec\n",
      "start training at epoch:113\n",
      "finished epoch 113: loss:140.825, lr: 0.000000, time: 0.297475sec\n",
      "start training at epoch:114\n",
      "finished epoch 114: loss:140.825, lr: 0.000000, time: 0.299524sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940799, MissRate:1.000000\n",
      "model saved to trained_params/epoch_114.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:115\n",
      "finished epoch 115: loss:140.825, lr: 0.000000, time: 0.305489sec\n",
      "start training at epoch:116\n",
      "finished epoch 116: loss:140.825, lr: 0.000000, time: 0.379844sec\n",
      "start training at epoch:117\n",
      "finished epoch 117: loss:140.825, lr: 0.000000, time: 0.302290sec\n",
      "start training at epoch:118\n",
      "epoch 118 step 119： loss:0.515717, lr: 0.000000, time: 0.293129sec\n",
      "finished epoch 118: loss:140.825, lr: 0.000000, time: 0.293537sec\n",
      "start training at epoch:119\n",
      "finished epoch 119: loss:140.825, lr: 0.000000, time: 0.299219sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "model saved to trained_params/epoch_119.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:120\n",
      "finished epoch 120: loss:140.825, lr: 0.000000, time: 0.299042sec\n",
      "start training at epoch:121\n",
      "finished epoch 121: loss:140.825, lr: 0.000000, time: 0.296803sec\n",
      "start training at epoch:122\n",
      "finished epoch 122: loss:140.825, lr: 0.000000, time: 0.297479sec\n",
      "start training at epoch:123\n",
      "finished epoch 123: loss:140.825, lr: 0.000000, time: 0.296721sec\n",
      "start training at epoch:124\n",
      "finished epoch 124: loss:140.825, lr: 0.000000, time: 0.292570sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:125\n",
      "finished epoch 125: loss:140.825, lr: 0.000000, time: 0.306437sec\n",
      "start training at epoch:126\n",
      "finished epoch 126: loss:140.825, lr: 0.000000, time: 0.293104sec\n",
      "start training at epoch:127\n",
      "finished epoch 127: loss:140.825, lr: 0.000000, time: 0.302922sec\n",
      "start training at epoch:128\n",
      "epoch 128 step 129： loss:0.515717, lr: 0.000000, time: 0.299842sec\n",
      "finished epoch 128: loss:140.825, lr: 0.000000, time: 0.300265sec\n",
      "start training at epoch:129\n",
      "finished epoch 129: loss:140.825, lr: 0.000000, time: 0.308327sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940799, MissRate:1.000000\n",
      "model saved to trained_params/epoch_129.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:130\n",
      "finished epoch 130: loss:140.825, lr: 0.000000, time: 0.243246sec\n",
      "start training at epoch:131\n",
      "finished epoch 131: loss:140.825, lr: 0.000000, time: 0.372934sec\n",
      "start training at epoch:132\n",
      "finished epoch 132: loss:140.825, lr: 0.000000, time: 0.295418sec\n",
      "start training at epoch:133\n",
      "finished epoch 133: loss:140.825, lr: 0.000000, time: 0.306621sec\n",
      "start training at epoch:134\n",
      "finished epoch 134: loss:140.825, lr: 0.000000, time: 0.297407sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "model saved to trained_params/epoch_134.valminade_12.485.200630.epochs500.lr_decay0.3.decay_every10.lr0.001.xkhuang.pth\n",
      "start training at epoch:135\n",
      "finished epoch 135: loss:140.825, lr: 0.000000, time: 0.301393sec\n",
      "start training at epoch:136\n",
      "finished epoch 136: loss:140.825, lr: 0.000000, time: 0.306461sec\n",
      "start training at epoch:137\n",
      "finished epoch 137: loss:140.825, lr: 0.000000, time: 0.293778sec\n",
      "start training at epoch:138\n",
      "epoch 138 step 139： loss:0.515717, lr: 0.000000, time: 0.300342sec\n",
      "finished epoch 138: loss:140.825, lr: 0.000000, time: 0.300712sec\n",
      "start training at epoch:139\n",
      "finished epoch 139: loss:140.825, lr: 0.000000, time: 0.300200sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:140\n",
      "finished epoch 140: loss:140.825, lr: 0.000000, time: 0.295674sec\n",
      "start training at epoch:141\n",
      "finished epoch 141: loss:140.825, lr: 0.000000, time: 0.297478sec\n",
      "start training at epoch:142\n",
      "finished epoch 142: loss:140.825, lr: 0.000000, time: 0.297494sec\n",
      "start training at epoch:143\n",
      "finished epoch 143: loss:140.825, lr: 0.000000, time: 0.305175sec\n",
      "start training at epoch:144\n",
      "finished epoch 144: loss:140.825, lr: 0.000000, time: 0.293631sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940799, MissRate:1.000000\n",
      "start training at epoch:145\n",
      "finished epoch 145: loss:140.825, lr: 0.000000, time: 0.319350sec\n",
      "start training at epoch:146\n",
      "finished epoch 146: loss:140.825, lr: 0.000000, time: 0.297164sec\n",
      "start training at epoch:147\n",
      "finished epoch 147: loss:140.825, lr: 0.000000, time: 0.297893sec\n",
      "start training at epoch:148\n",
      "epoch 148 step 149： loss:0.515717, lr: 0.000000, time: 0.296718sec\n",
      "finished epoch 148: loss:140.825, lr: 0.000000, time: 0.297090sec\n",
      "start training at epoch:149\n",
      "finished epoch 149: loss:140.825, lr: 0.000000, time: 0.314267sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:150\n",
      "finished epoch 150: loss:140.825, lr: 0.000000, time: 0.311613sec\n",
      "start training at epoch:151\n",
      "finished epoch 151: loss:140.825, lr: 0.000000, time: 0.351236sec\n",
      "start training at epoch:152\n",
      "finished epoch 152: loss:140.825, lr: 0.000000, time: 0.245972sec\n",
      "start training at epoch:153\n",
      "finished epoch 153: loss:140.825, lr: 0.000000, time: 0.299364sec\n",
      "start training at epoch:154\n",
      "finished epoch 154: loss:140.825, lr: 0.000000, time: 0.297614sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:155\n",
      "finished epoch 155: loss:140.825, lr: 0.000000, time: 0.298198sec\n",
      "start training at epoch:156\n",
      "finished epoch 156: loss:140.825, lr: 0.000000, time: 0.301277sec\n",
      "start training at epoch:157\n",
      "finished epoch 157: loss:140.825, lr: 0.000000, time: 0.242510sec\n",
      "start training at epoch:158\n",
      "epoch 158 step 159： loss:0.515717, lr: 0.000000, time: 0.299032sec\n",
      "finished epoch 158: loss:140.825, lr: 0.000000, time: 0.351817sec\n",
      "start training at epoch:159\n",
      "finished epoch 159: loss:140.825, lr: 0.000000, time: 0.241921sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:160\n",
      "finished epoch 160: loss:140.825, lr: 0.000000, time: 0.301806sec\n",
      "start training at epoch:161\n",
      "finished epoch 161: loss:140.825, lr: 0.000000, time: 0.298836sec\n",
      "start training at epoch:162\n",
      "finished epoch 162: loss:140.825, lr: 0.000000, time: 0.298855sec\n",
      "start training at epoch:163\n",
      "finished epoch 163: loss:140.825, lr: 0.000000, time: 0.303345sec\n",
      "start training at epoch:164\n",
      "finished epoch 164: loss:140.825, lr: 0.000000, time: 0.302762sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:165\n",
      "finished epoch 165: loss:140.825, lr: 0.000000, time: 0.299881sec\n",
      "start training at epoch:166\n",
      "finished epoch 166: loss:140.825, lr: 0.000000, time: 0.299383sec\n",
      "start training at epoch:167\n",
      "finished epoch 167: loss:140.825, lr: 0.000000, time: 0.301539sec\n",
      "start training at epoch:168\n",
      "epoch 168 step 169： loss:0.515717, lr: 0.000000, time: 0.299495sec\n",
      "finished epoch 168: loss:140.825, lr: 0.000000, time: 0.300000sec\n",
      "start training at epoch:169\n",
      "finished epoch 169: loss:140.825, lr: 0.000000, time: 0.302512sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:170\n",
      "finished epoch 170: loss:140.825, lr: 0.000000, time: 0.297856sec\n",
      "start training at epoch:171\n",
      "finished epoch 171: loss:140.825, lr: 0.000000, time: 0.298238sec\n",
      "start training at epoch:172\n",
      "finished epoch 172: loss:140.825, lr: 0.000000, time: 0.306173sec\n",
      "start training at epoch:173\n",
      "finished epoch 173: loss:140.825, lr: 0.000000, time: 0.294451sec\n",
      "start training at epoch:174\n",
      "finished epoch 174: loss:140.825, lr: 0.000000, time: 0.318555sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:175\n",
      "finished epoch 175: loss:140.825, lr: 0.000000, time: 0.302010sec\n",
      "start training at epoch:176\n",
      "finished epoch 176: loss:140.825, lr: 0.000000, time: 0.298935sec\n",
      "start training at epoch:177\n",
      "finished epoch 177: loss:140.825, lr: 0.000000, time: 0.297205sec\n",
      "start training at epoch:178\n",
      "epoch 178 step 179： loss:0.515717, lr: 0.000000, time: 0.296952sec\n",
      "finished epoch 178: loss:140.825, lr: 0.000000, time: 0.297333sec\n",
      "start training at epoch:179\n",
      "finished epoch 179: loss:140.825, lr: 0.000000, time: 0.300441sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:180\n",
      "finished epoch 180: loss:140.825, lr: 0.000000, time: 0.364835sec\n",
      "start training at epoch:181\n",
      "finished epoch 181: loss:140.825, lr: 0.000000, time: 0.300964sec\n",
      "start training at epoch:182\n",
      "finished epoch 182: loss:140.825, lr: 0.000000, time: 0.298327sec\n",
      "start training at epoch:183\n",
      "finished epoch 183: loss:140.825, lr: 0.000000, time: 0.306238sec\n",
      "start training at epoch:184\n",
      "finished epoch 184: loss:140.825, lr: 0.000000, time: 0.301181sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:185\n",
      "finished epoch 185: loss:140.825, lr: 0.000000, time: 0.306972sec\n",
      "start training at epoch:186\n",
      "finished epoch 186: loss:140.825, lr: 0.000000, time: 0.302511sec\n",
      "start training at epoch:187\n",
      "finished epoch 187: loss:140.825, lr: 0.000000, time: 0.299564sec\n",
      "start training at epoch:188\n",
      "epoch 188 step 189： loss:0.515717, lr: 0.000000, time: 0.371575sec\n",
      "finished epoch 188: loss:140.825, lr: 0.000000, time: 0.372066sec\n",
      "start training at epoch:189\n",
      "finished epoch 189: loss:140.825, lr: 0.000000, time: 0.302540sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:190\n",
      "finished epoch 190: loss:140.825, lr: 0.000000, time: 0.302796sec\n",
      "start training at epoch:191\n",
      "finished epoch 191: loss:140.825, lr: 0.000000, time: 0.302102sec\n",
      "start training at epoch:192\n",
      "finished epoch 192: loss:140.825, lr: 0.000000, time: 0.300514sec\n",
      "start training at epoch:193\n",
      "finished epoch 193: loss:140.825, lr: 0.000000, time: 0.301197sec\n",
      "start training at epoch:194\n",
      "finished epoch 194: loss:140.825, lr: 0.000000, time: 0.296618sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:195\n",
      "finished epoch 195: loss:140.825, lr: 0.000000, time: 0.298142sec\n",
      "start training at epoch:196\n",
      "finished epoch 196: loss:140.825, lr: 0.000000, time: 0.301598sec\n",
      "start training at epoch:197\n",
      "finished epoch 197: loss:140.825, lr: 0.000000, time: 0.302036sec\n",
      "start training at epoch:198\n",
      "epoch 198 step 199： loss:0.515717, lr: 0.000000, time: 0.293662sec\n",
      "finished epoch 198: loss:140.825, lr: 0.000000, time: 0.294049sec\n",
      "start training at epoch:199\n",
      "finished epoch 199: loss:140.825, lr: 0.000000, time: 0.246638sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:200\n",
      "finished epoch 200: loss:140.825, lr: 0.000000, time: 0.303895sec\n",
      "start training at epoch:201\n",
      "finished epoch 201: loss:140.825, lr: 0.000000, time: 0.297904sec\n",
      "start training at epoch:202\n",
      "finished epoch 202: loss:140.825, lr: 0.000000, time: 0.309606sec\n",
      "start training at epoch:203\n",
      "finished epoch 203: loss:140.825, lr: 0.000000, time: 0.315001sec\n",
      "start training at epoch:204\n",
      "finished epoch 204: loss:140.825, lr: 0.000000, time: 0.293071sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:205\n",
      "finished epoch 205: loss:140.825, lr: 0.000000, time: 0.297753sec\n",
      "start training at epoch:206\n",
      "finished epoch 206: loss:140.825, lr: 0.000000, time: 0.301237sec\n",
      "start training at epoch:207\n",
      "finished epoch 207: loss:140.825, lr: 0.000000, time: 0.373702sec\n",
      "start training at epoch:208\n",
      "epoch 208 step 209： loss:0.515717, lr: 0.000000, time: 0.300866sec\n",
      "finished epoch 208: loss:140.825, lr: 0.000000, time: 0.301234sec\n",
      "start training at epoch:209\n",
      "finished epoch 209: loss:140.825, lr: 0.000000, time: 0.301070sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:210\n",
      "finished epoch 210: loss:140.825, lr: 0.000000, time: 0.305272sec\n",
      "start training at epoch:211\n",
      "finished epoch 211: loss:140.825, lr: 0.000000, time: 0.298612sec\n",
      "start training at epoch:212\n",
      "finished epoch 212: loss:140.825, lr: 0.000000, time: 0.297983sec\n",
      "start training at epoch:213\n",
      "finished epoch 213: loss:140.825, lr: 0.000000, time: 0.301342sec\n",
      "start training at epoch:214\n",
      "finished epoch 214: loss:140.825, lr: 0.000000, time: 0.297666sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:215\n",
      "finished epoch 215: loss:140.825, lr: 0.000000, time: 0.298145sec\n",
      "start training at epoch:216\n",
      "finished epoch 216: loss:140.825, lr: 0.000000, time: 0.296690sec\n",
      "start training at epoch:217\n",
      "finished epoch 217: loss:140.825, lr: 0.000000, time: 0.371596sec\n",
      "start training at epoch:218\n",
      "epoch 218 step 219： loss:0.515717, lr: 0.000000, time: 0.297018sec\n",
      "finished epoch 218: loss:140.825, lr: 0.000000, time: 0.297390sec\n",
      "start training at epoch:219\n",
      "finished epoch 219: loss:140.825, lr: 0.000000, time: 0.300938sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:220\n",
      "finished epoch 220: loss:140.825, lr: 0.000000, time: 0.300864sec\n",
      "start training at epoch:221\n",
      "finished epoch 221: loss:140.825, lr: 0.000000, time: 0.298008sec\n",
      "start training at epoch:222\n",
      "finished epoch 222: loss:140.825, lr: 0.000000, time: 0.296851sec\n",
      "start training at epoch:223\n",
      "finished epoch 223: loss:140.825, lr: 0.000000, time: 0.301800sec\n",
      "start training at epoch:224\n",
      "finished epoch 224: loss:140.825, lr: 0.000000, time: 0.296803sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:225\n",
      "finished epoch 225: loss:140.825, lr: 0.000000, time: 0.301364sec\n",
      "start training at epoch:226\n",
      "finished epoch 226: loss:140.825, lr: 0.000000, time: 0.300434sec\n",
      "start training at epoch:227\n",
      "finished epoch 227: loss:140.825, lr: 0.000000, time: 0.301178sec\n",
      "start training at epoch:228\n",
      "epoch 228 step 229： loss:0.515717, lr: 0.000000, time: 0.300602sec\n",
      "finished epoch 228: loss:140.825, lr: 0.000000, time: 0.300982sec\n",
      "start training at epoch:229\n",
      "finished epoch 229: loss:140.825, lr: 0.000000, time: 0.296924sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:230\n",
      "finished epoch 230: loss:140.825, lr: 0.000000, time: 0.301004sec\n",
      "start training at epoch:231\n",
      "finished epoch 231: loss:140.825, lr: 0.000000, time: 0.372826sec\n",
      "start training at epoch:232\n",
      "finished epoch 232: loss:140.825, lr: 0.000000, time: 0.305894sec\n",
      "start training at epoch:233\n",
      "finished epoch 233: loss:140.825, lr: 0.000000, time: 0.297366sec\n",
      "start training at epoch:234\n",
      "finished epoch 234: loss:140.825, lr: 0.000000, time: 0.301633sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:235\n",
      "finished epoch 235: loss:140.825, lr: 0.000000, time: 0.300341sec\n",
      "start training at epoch:236\n",
      "finished epoch 236: loss:140.825, lr: 0.000000, time: 0.300006sec\n",
      "start training at epoch:237\n",
      "finished epoch 237: loss:140.825, lr: 0.000000, time: 0.293125sec\n",
      "start training at epoch:238\n",
      "epoch 238 step 239： loss:0.515717, lr: 0.000000, time: 0.316309sec\n",
      "finished epoch 238: loss:140.825, lr: 0.000000, time: 0.316764sec\n",
      "start training at epoch:239\n",
      "finished epoch 239: loss:140.825, lr: 0.000000, time: 0.300319sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:240\n",
      "finished epoch 240: loss:140.825, lr: 0.000000, time: 0.310570sec\n",
      "start training at epoch:241\n",
      "finished epoch 241: loss:140.825, lr: 0.000000, time: 0.298423sec\n",
      "start training at epoch:242\n",
      "finished epoch 242: loss:140.825, lr: 0.000000, time: 0.293166sec\n",
      "start training at epoch:243\n",
      "finished epoch 243: loss:140.825, lr: 0.000000, time: 0.309829sec\n",
      "start training at epoch:244\n",
      "finished epoch 244: loss:140.825, lr: 0.000000, time: 0.299769sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:245\n",
      "finished epoch 245: loss:140.825, lr: 0.000000, time: 0.374445sec\n",
      "start training at epoch:246\n",
      "finished epoch 246: loss:140.825, lr: 0.000000, time: 0.246820sec\n",
      "start training at epoch:247\n",
      "finished epoch 247: loss:140.825, lr: 0.000000, time: 0.299968sec\n",
      "start training at epoch:248\n",
      "epoch 248 step 249： loss:0.515717, lr: 0.000000, time: 0.243453sec\n",
      "finished epoch 248: loss:140.825, lr: 0.000000, time: 0.300075sec\n",
      "start training at epoch:249\n",
      "finished epoch 249: loss:140.825, lr: 0.000000, time: 0.246514sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:250\n",
      "finished epoch 250: loss:140.825, lr: 0.000000, time: 0.298202sec\n",
      "start training at epoch:251\n",
      "finished epoch 251: loss:140.825, lr: 0.000000, time: 0.297715sec\n",
      "start training at epoch:252\n",
      "finished epoch 252: loss:140.825, lr: 0.000000, time: 0.300975sec\n",
      "start training at epoch:253\n",
      "finished epoch 253: loss:140.825, lr: 0.000000, time: 0.293578sec\n",
      "start training at epoch:254\n",
      "finished epoch 254: loss:140.825, lr: 0.000000, time: 0.301716sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:255\n",
      "finished epoch 255: loss:140.825, lr: 0.000000, time: 0.298051sec\n",
      "start training at epoch:256\n",
      "finished epoch 256: loss:140.825, lr: 0.000000, time: 0.297381sec\n",
      "start training at epoch:257\n",
      "finished epoch 257: loss:140.825, lr: 0.000000, time: 0.300607sec\n",
      "start training at epoch:258\n",
      "epoch 258 step 259： loss:0.515717, lr: 0.000000, time: 0.301601sec\n",
      "finished epoch 258: loss:140.825, lr: 0.000000, time: 0.301952sec\n",
      "start training at epoch:259\n",
      "finished epoch 259: loss:140.825, lr: 0.000000, time: 0.324451sec\n",
      "eval as epoch:{epoch}\n",
      "minADE:12.484905, minFDE:24.940798, MissRate:1.000000\n",
      "start training at epoch:260\n",
      "finished epoch 260: loss:140.825, lr: 0.000000, time: 0.303296sec\n",
      "start training at epoch:261\n",
      "finished epoch 261: loss:140.825, lr: 0.000000, time: 0.301123sec\n",
      "start training at epoch:262\n",
      "finished epoch 262: loss:140.825, lr: 0.000000, time: 0.302712sec\n",
      "start training at epoch:263\n",
      "finished epoch 263: loss:140.825, lr: 0.000000, time: 0.299145sec\n",
      "start training at epoch:264\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2020-05-27 15:00\n",
    "# @Author  : Xiaoke Huang\n",
    "# @Email   : xiaokehuang@foxmail.com\n",
    "\n",
    "# @Editor-Time   :2024-06-26 21:14\n",
    "# @Editor-Author :daetz\n",
    "\n",
    "from modeling.vectornet import HGNN\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.viz_utils import show_predict_result\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pdb\n",
    "import os\n",
    "from dataset import GraphDataset\n",
    "#from torch_geometric.data import DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from utils.eval import get_eval_metric_results\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "# %%\n",
    "TRAIN_DIR = os.path.join('interm_data', 'train_intermediate')\n",
    "VAL_DIR = os.path.join('interm_data', 'val_intermediate')\n",
    "SEED = 13\n",
    "epochs = 100\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 4096\n",
    "decay_lr_factor = 0.3\n",
    "decay_lr_every = 10\n",
    "lr = 0.001\n",
    "in_channels, out_channels = 8, 60\n",
    "show_every = 10\n",
    "val_every = 5\n",
    "small_dataset = False\n",
    "end_epoch = 0\n",
    "save_dir = 'trained_params'\n",
    "best_minade = float('inf')\n",
    "date = f\"200630.epochs{epochs}.lr_decay{decay_lr_factor}.decay_every{decay_lr_every}.lr{lr}\"\n",
    "global_step = 0\n",
    "# checkpoint_dir = os.path.join('trained_params', 'epoch_6.valminade_3.796.pth')\n",
    "checkpoint_dir = None\n",
    "# eval related\n",
    "max_n_guesses = 1\n",
    "horizon = 30\n",
    "miss_threshold = 2.0\n",
    "\n",
    "\n",
    "#%%\n",
    "#%%\n",
    "def save_checkpoint(checkpoint_dir, model, optimizer, end_epoch, val_minade, date):\n",
    "    # state_dict: a Python dictionary object that:\n",
    "    # - for a model, maps each layer to its parameter tensor;\n",
    "    # - for an optimizer, contains info about the optimizerâ€™s states and hyperparameters used.\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    state = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "        'end_epoch' : end_epoch,\n",
    "        'val_minade': val_minade\n",
    "        }\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'epoch_{end_epoch}.valminade_{val_minade:.3f}.{date}.{\"xkhuang\"}.pth')\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from %s' % checkpoint_path)\n",
    "\n",
    "\n",
    "#%%\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    # hyper parameters\n",
    "\n",
    "    train_data = GraphDataset(TRAIN_DIR).shuffle()\n",
    "    val_data = GraphDataset(VAL_DIR)\n",
    "    if small_dataset:\n",
    "        train_loader = DataLoader(train_data[:20], batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_data[:10], batch_size=batch_size)\n",
    "    else:\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "\n",
    "    model = HGNN(in_channels, out_channels).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size=decay_lr_every, gamma=decay_lr_factor)\n",
    "    if checkpoint_dir:\n",
    "        load_checkpoint(checkpoint_dir, model, optimizer)\n",
    "\n",
    "    # overfit the small dataset\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"start training at epoch:{epoch}\")\n",
    "        acc_loss = .0\n",
    "        num_samples = 1\n",
    "        start_tic = time.time()\n",
    "        for data in train_loader:\n",
    "            if epoch < end_epoch: break\n",
    "            if isinstance(data, List):\n",
    "                y = torch.cat([i.y for i in data], 0).view(-1, out_channels).to(device)\n",
    "            else:\n",
    "                data = data.to(device)\n",
    "                y = data.y.view(-1, out_channels)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = F.mse_loss(out, y)\n",
    "            loss.backward()\n",
    "            acc_loss += batch_size * loss.item()\n",
    "            num_samples += y.shape[0]\n",
    "            optimizer.step()\n",
    "            global_step += 1\n",
    "            if (global_step + 1) % show_every == 0:\n",
    "                print( f\"epoch {epoch} step {global_step}： loss:{loss.item():3f}, lr:{optimizer.state_dict()['param_groups'][0]['lr']: .6f}, time:{time.time() - start_tic: 4f}sec\")\n",
    "        scheduler.step()\n",
    "        print(\n",
    "            f\"finished epoch {epoch}: loss:{acc_loss / num_samples:.3f}, lr:{optimizer.state_dict()['param_groups'][0]['lr']: .6f}, time:{time.time() - start_tic: 4f}sec\")\n",
    "        \n",
    "        if (epoch+1) % val_every == 0 and (not epoch < end_epoch):\n",
    "            print(\"eval as epoch:{epoch}\")\n",
    "            metrics = get_eval_metric_results(model, val_loader, device, out_channels, max_n_guesses, horizon, miss_threshold)\n",
    "            curr_minade = metrics[\"minADE\"]\n",
    "            print(f\"minADE:{metrics['minADE']:3f}, minFDE:{metrics['minFDE']:3f}, MissRate:{metrics['MR']:3f}\")\n",
    "\n",
    "            if curr_minade < best_minade:\n",
    "                best_minade = curr_minade\n",
    "                save_checkpoint(save_dir, model, optimizer, epoch, best_minade, date)\n",
    "                \n",
    "    # eval result on the identity dataset\n",
    "    metrics = get_eval_metric_results(model, val_loader, device, out_channels, max_n_guesses, horizon, miss_threshold)\n",
    "    curr_minade = metrics[\"minADE\"]\n",
    "    if curr_minade < best_minade:\n",
    "        best_minade = curr_minade\n",
    "        save_checkpoint(save_dir, model, optimizer, -1, best_minade, date)\n",
    "\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a4b16-6535-41ad-a71d-6f76155f87a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
